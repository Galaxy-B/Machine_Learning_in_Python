{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data and feature name from excel file\n",
    "def read_data(path = None):\n",
    "    df = pd.read_excel(path)\n",
    "\n",
    "    # delete column 'nameid'\n",
    "    df = df.drop(['nameid'], axis = 1)\n",
    "\n",
    "    # discretize feature 'revenue'\n",
    "    threshold = [0,10000,20000,30000,40000,50000]\n",
    "    df['revenue'] = pd.cut(df['revenue'], threshold, labels = False)\n",
    "\n",
    "    # fetch dataset and names of each feature\n",
    "    dataset = df.values\n",
    "    features = df.columns.values\n",
    "\n",
    "    return dataset, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     profession  education  house_loan  car_loan  married  child  revenue  \\\n",
      "0             5          1           0         0        1      1        0   \n",
      "1             3          1           1         1        0      0        0   \n",
      "2             2          3           1         0        1      0        1   \n",
      "3             2          2           0         0        0      0        4   \n",
      "4             4          2           0         1        0      1        1   \n",
      "..          ...        ...         ...       ...      ...    ...      ...   \n",
      "795           5          3           0         1        1      0        2   \n",
      "796           5          5           0         0        1      1        3   \n",
      "797           1          1           0         0        1      0        2   \n",
      "798           3          5           0         1        0      0        1   \n",
      "799           1          4           0         0        1      0        3   \n",
      "\n",
      "     approve  \n",
      "0          1  \n",
      "1          0  \n",
      "2          1  \n",
      "3          1  \n",
      "4          0  \n",
      "..       ...  \n",
      "795        1  \n",
      "796        1  \n",
      "797        1  \n",
      "798        1  \n",
      "799        1  \n",
      "\n",
      "[800 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# read dataset for training\n",
    "train_dataset, train_features = read_data(r\"train.xls\")\n",
    "train_data = pd.DataFrame(train_dataset, columns = train_features)\n",
    "\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     profession  education  house_loan  car_loan  married  child  revenue  \\\n",
      "0             1          4           1         1        1      1        1   \n",
      "1             2          1           0         0        1      0        4   \n",
      "2             5          5           1         1        0      1        4   \n",
      "3             5          5           1         0        1      0        1   \n",
      "4             3          3           0         1        1      1        1   \n",
      "..          ...        ...         ...       ...      ...    ...      ...   \n",
      "195           3          2           1         1        0      0        3   \n",
      "196           3          5           0         0        0      0        3   \n",
      "197           4          2           1         1        0      1        1   \n",
      "198           4          1           0         0        0      0        3   \n",
      "199           5          4           0         1        1      1        1   \n",
      "\n",
      "     approve  \n",
      "0          0  \n",
      "1          1  \n",
      "2          0  \n",
      "3          1  \n",
      "4          1  \n",
      "..       ...  \n",
      "195        1  \n",
      "196        1  \n",
      "197        0  \n",
      "198        1  \n",
      "199        1  \n",
      "\n",
      "[200 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# read dataset for test\n",
    "test_dataset, test_features = read_data(r\"test.xls\")\n",
    "test_data = pd.DataFrame(test_dataset, columns = test_features)\n",
    "\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class for node of N-ary tree\n",
    "class Tree_Node:\n",
    "    def __init__(self, isleaf = True, label = None, feature_name = None, feature_num = None) -> None:\n",
    "        self.isleaf = isleaf                # if this node is a leaf \n",
    "        self.label = label                  # label of the node if it is a leaf\n",
    "        self.feature_name = feature_name    # name of its feature\n",
    "        self.feature_num = feature_num      # number of its feature\n",
    "        self.children = {}                  # children of this node\n",
    "        self.result = {'label' : self.label, 'feature' : self.feature_num, 'children' : self.children}\n",
    "\n",
    "    # fetch the info of this node\n",
    "    def __repr__(self) -> str:\n",
    "        return '{}'.format(self.result)\n",
    "    \n",
    "    # add a new child to this node\n",
    "    def add_child(self, val, node) -> None:\n",
    "        self.children[val] = node\n",
    "\n",
    "    # predict the result base on given feature set\n",
    "    def predict(self, features) -> int:\n",
    "        # if this node turns out to be a leaf, just return its label\n",
    "        if self.isleaf is True:\n",
    "            return self.label\n",
    "        \n",
    "        # if the input feature value for this node is not valid\n",
    "        if features[self.feature_num] not in self.children.keys():\n",
    "            # fetch all valid values and pick a random one\n",
    "            valid_feature_value_index = list(self.children.keys())\n",
    "            x = np.random.randint(0, len(valid_feature_value_index) - 1)\n",
    "            random_feature_value = valid_feature_value_index[x]\n",
    "            \n",
    "            # go on predicting on this randomly-chosen subtree\n",
    "            return self.children[random_feature_value].predict(features)\n",
    "        \n",
    "        # otherwise just keep our prediction going\n",
    "        return self.children[features[self.feature_num]].predict(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class for decision tree\n",
    "class Decision_Tree:\n",
    "    def __init__(self, epsilon = 0.01) -> None:\n",
    "        self.epsilon = epsilon              # threshold of gain ratio\n",
    "\n",
    "    # calculate empirical entropy\n",
    "    def calc_entropy(self, dataset) -> float:\n",
    "        data_len = len(dataset)\n",
    "        \n",
    "        # count the frequency of each label\n",
    "        label_count = {}\n",
    "        for i in range(data_len):\n",
    "            label = dataset[i][-1]\n",
    "            if label not in label_count:\n",
    "                label_count[label] = 0\n",
    "            label_count[label] += 1\n",
    "        \n",
    "        entropy = sum([(cnt / data_len) * log(cnt / data_len, 2) for cnt in label_count.values()])\n",
    "        return -entropy\n",
    "\n",
    "    # calculate empirical conditional entropy\n",
    "    def calc_cond_entropy(self, dataset, col = 0) -> float:\n",
    "        data_len = len(dataset)\n",
    "        \n",
    "        # partition dataset according to given feature\n",
    "        subsets = {}\n",
    "        for i in range(data_len):\n",
    "            feature_val = dataset[i][col]\n",
    "            if feature_val not in subsets:\n",
    "                subsets[feature_val] = []\n",
    "            subsets[feature_val].append(dataset[i])\n",
    "        \n",
    "        cond_entropy = sum([(len(set) / data_len) * self.calc_entropy(set) for set in subsets.values()])\n",
    "        return cond_entropy\n",
    "\n",
    "    # calculate the entropy of dataset about a certain feature\n",
    "    def calc_axis_entropy(self, dataset, col = 0) -> float:\n",
    "        data_len = len(dataset)\n",
    "        \n",
    "        # count the frequency of each value of this feature\n",
    "        value_count = {}\n",
    "        for i in range(data_len):\n",
    "            value = dataset[i][col]\n",
    "            if value not in value_count:\n",
    "                value_count[value] = 0\n",
    "            value_count[value] += 1\n",
    "\n",
    "        col_entropy = sum([(cnt / data_len) * log(cnt / data_len, 2) for cnt in value_count.values()])\n",
    "        return -col_entropy\n",
    "\n",
    "    # calculate gain ratio\n",
    "    def cal_gain_ratio(self, entropy, cond_entropy, col_entropy) -> float:\n",
    "        # be careful that col_entropy may be 0\n",
    "        critical_val = 1e-7\n",
    "        if -critical_val <= col_entropy and col_entropy <= critical_val:\n",
    "            return 0\n",
    "        else:\n",
    "            return (entropy - cond_entropy) / col_entropy \n",
    "\n",
    "    # find out the feature which holds the maxinum of gain ratio\n",
    "    def gain_ratio_train(self, dataset):\n",
    "        feature_count = len(dataset[0]) - 1\n",
    "        \n",
    "        # calculate the empirical entropy of the dataset\n",
    "        entropy = self.calc_entropy(dataset)\n",
    "        feature_ratio = []\n",
    "        for i in range(feature_count):\n",
    "            # calculate the gain ratio of each feature\n",
    "            i_cond_entropy = self.calc_cond_entropy(dataset, col = i)\n",
    "            i_col_entropy = self.calc_axis_entropy(dataset, col = i)\n",
    "            i_gain_ratio = self.cal_gain_ratio(entropy, i_cond_entropy, i_col_entropy)\n",
    "            feature_ratio.append((i, i_gain_ratio))\n",
    "        \n",
    "        best_feature = max(feature_ratio, key = lambda x: x[-1])\n",
    "        return best_feature\n",
    "\n",
    "    # input : dataset in DataFrame, feature set, threshold\n",
    "    # output: decision tree\n",
    "    def train(self, train_data):\n",
    "        labels, features = train_data.iloc[:, -1], train_data.columns[:-1]\n",
    "        \n",
    "        # this node would be a leaf if there is only one kind of label\n",
    "        if len(labels.value_counts()) == 1:\n",
    "            return Tree_Node(isleaf = True, label = labels.iloc[0])\n",
    "\n",
    "        # if the feature set is empty, another leaf, pick the major label for this node\n",
    "        if len(features) == 0:\n",
    "            return Tree_Node(isleaf = True, label = labels.value_counts().sort_values(ascending = False).index[0])\n",
    "\n",
    "        # otherwise find out the feature which holds the maxinum of gain ratio\n",
    "        best_feature, max_gain_ratio = self.gain_ratio_train(np.array(train_data))\n",
    "        best_feature_name = features[best_feature]\n",
    "\n",
    "        # if the gain ratio is less then threshold, another leaf, pick the major label for this node\n",
    "        if max_gain_ratio < self.epsilon:\n",
    "            return Tree_Node(isleaf = True, label = labels.value_counts().sort_values(ascending = False).index[0])\n",
    "\n",
    "        # otherwise go on building the tree recursively\n",
    "        node = Tree_Node(isleaf = False, feature_name = best_feature_name, feature_num = best_feature)\n",
    "\n",
    "        # build a subtree for each value of this feature separately\n",
    "        feature_values = train_data[best_feature_name].value_counts().index\n",
    "        for val in feature_values:\n",
    "            # pick all data of this feature value, and delete this used feature\n",
    "            sub_train_data = train_data.loc[train_data[best_feature_name] == val].drop([best_feature_name], axis = 1)\n",
    "            sub_tree = self.train(sub_train_data)\n",
    "            node.add_child(val, sub_tree)\n",
    "        \n",
    "        return node\n",
    "\n",
    "    # build the decision tree according to given dataset, and return the root node   \n",
    "    def fit(self, train_data):\n",
    "        self.root = self.train(train_data)\n",
    "        return self.root\n",
    "\n",
    "    def predict(self, test_data):\n",
    "        return self.root.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build decision tree\n",
    "dt_model = Decision_Tree()\n",
    "root = dt_model.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  1.0\n",
      "Recall:  0.6987951807228916\n",
      "F1-score:  0.8226950354609929\n"
     ]
    }
   ],
   "source": [
    "# use test dataset to estimate the performance of the model\n",
    "result = []\n",
    "for i in range(len(test_data)):\n",
    "    example = test_data.iloc[i, :-1].values.tolist()\n",
    "    result.append(root.predict(example))\n",
    "\n",
    "# find the indicators that we need\n",
    "TP, FP, FN, TN = 0, 0, 0, 0\n",
    "for i in range(len(test_data)):\n",
    "    if test_data.iloc[i, -1] == 1:\n",
    "        if result[i] == 1:\n",
    "            TP += 1\n",
    "        else:\n",
    "            FN += 1\n",
    "    else:\n",
    "        if result[i] == 1:\n",
    "            FP += 1\n",
    "        else:\n",
    "            TN += 1\n",
    "\n",
    "# calculate Precision Recall and F1-score\n",
    "P = TP / (TP + FP)\n",
    "R = TP / (TP + FN)\n",
    "F1 = 2 * TP / (2 * TP + FP + FN)\n",
    "\n",
    "print(\"Precision: \", P)\n",
    "print(\"Recall: \", R)\n",
    "print(\"F1-score: \", F1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
