{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrangle the given data file and write the result into a new file\n",
    "def wrangle(file_name = None):\n",
    "    \n",
    "    old_path = file_name + '.csv'\n",
    "    new_path = file_name + '_wrangled.csv'\n",
    "\n",
    "    old_data = pd.read_csv(old_path, encoding = 'gbk')\n",
    "\n",
    "    # fetch the total consumption frequency of each customer\n",
    "    frequency = old_data['USER_ID'].value_counts()\n",
    "    frequency = frequency.reset_index()\n",
    "    frequency.columns = ['USER_ID', 'frequency']\n",
    "\n",
    "    # fetch the total consumption of each customer\n",
    "    consumption = old_data[['number_consumers', \"expenditure\"]].groupby(old_data['USER_ID']).sum()\n",
    "    consumption = consumption.reset_index()\n",
    "    consumption.columns = ['USER_ID', 'total_number', 'total_expenditure']\n",
    "\n",
    "    # merge this two tables above\n",
    "    new_data = pd.merge(frequency, consumption, left_on = 'USER_ID', right_on = 'USER_ID', how = 'left')\n",
    "\n",
    "    # fetch the label of each customer\n",
    "    labels = old_data.iloc[:, :4]\n",
    "    labels = labels.groupby(['USER_ID']).last()\n",
    "    labels = labels.reset_index()\n",
    "\n",
    "    # merge labels into new data\n",
    "    new_data = pd.merge(new_data, labels, left_on = 'USER_ID', right_on = 'USER_ID', how = 'left')\n",
    "\n",
    "    # drop the records which contain NaN or hold 0 value for 'total_number'\n",
    "    new_data = new_data.dropna(axis = 0)\n",
    "    new_data = new_data[new_data['total_number'] != 0]\n",
    "\n",
    "    # calculate the per capita consumption of each customer\n",
    "    new_data['aver_consumption'] = new_data['total_expenditure'] / new_data['total_number']\n",
    "    new_data['aver_consumption'] = new_data['aver_consumption'].apply(lambda x: '%.2f' % x)\n",
    "\n",
    "    # fetch the last consumption date by the end of observation period \n",
    "    new_data['last_visit'] = pd.to_datetime(new_data['LAST_VISITS'])\n",
    "    end_date = pd.to_datetime('2016-7-31')\n",
    "    gaps = end_date - new_data['last_visit']\n",
    "    new_data['last_visit'] = gaps.apply(lambda x: x.days)\n",
    "\n",
    "    # write the wrangled data into a new file\n",
    "    new_data = new_data.loc[:, ['USER_ID', 'frequency', 'total_expenditure', 'aver_consumption', 'last_visit', 'type']]\n",
    "    new_data.to_csv(new_path, index = False, encoding = 'gbk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrangle the train data and the test data\n",
    "wrangle('train')\n",
    "wrangle('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from the given file\n",
    "def read_data(path = None):\n",
    "\n",
    "    df = pd.read_csv(path, encoding = 'gbk')\n",
    "    # drop the USER_ID column\n",
    "    df = df.drop(['USER_ID'], axis = 1)\n",
    "    # convert labels into digits\n",
    "    df = df.replace('非流失', 0)\n",
    "    df = df.replace('准流失', 1)\n",
    "    # fetch data set and feature names\n",
    "    dataset = df.values\n",
    "    feature_name = df.columns.values\n",
    "\n",
    "    return dataset, feature_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      frequency  total_expenditure  aver_consumption  last_visit  type\n",
      "0          37.0            33570.0            145.32         3.0   0.0\n",
      "1          34.0            31903.0            142.42         4.0   0.0\n",
      "2          33.0            30400.0            152.76         8.0   0.0\n",
      "3          33.0            30849.0            155.80         7.0   0.0\n",
      "4          32.0            28695.0            145.66         1.0   0.0\n",
      "...         ...                ...               ...         ...   ...\n",
      "1473        1.0             1432.0            159.11       106.0   1.0\n",
      "1474        1.0              440.0            220.00        65.0   1.0\n",
      "1475        1.0             1568.0            156.80        57.0   1.0\n",
      "1476        1.0              785.0            112.14        49.0   1.0\n",
      "1477        1.0             1012.0            126.50        98.0   1.0\n",
      "\n",
      "[1478 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# read train data\n",
    "train_dataset, train_features = read_data(r\"train_wrangled.csv\")\n",
    "train_data = pd.DataFrame(train_dataset, columns = train_features)\n",
    "\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     frequency  total_expenditure  aver_consumption  last_visit  type\n",
      "0         41.0            34784.0            146.77         0.0   0.0\n",
      "1         33.0            32699.0            157.97         2.0   0.0\n",
      "2         33.0            30394.0            146.12         3.0   0.0\n",
      "3         32.0            27088.0            141.08         5.0   0.0\n",
      "4         25.0            18910.0            163.02         5.0   0.0\n",
      "..         ...                ...               ...         ...   ...\n",
      "429        1.0              358.0            119.33        20.0   1.0\n",
      "430        1.0             1433.0            159.22        49.0   1.0\n",
      "431        1.0             1259.0            179.86        42.0   1.0\n",
      "432        1.0             1602.0            160.20        41.0   1.0\n",
      "433        1.0              469.0             78.17       106.0   1.0\n",
      "\n",
      "[434 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# read test data\n",
    "test_dataset, test_features = read_data(r\"test_wrangled.csv\")\n",
    "test_data = pd.DataFrame(test_dataset, columns = test_features)\n",
    "\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# devide the data set into train set and test set\n",
    "X_train = np.array(train_data.iloc[:, :-1])\n",
    "Y_train = np.array(train_data.iloc[:, -1])\n",
    "\n",
    "X_test = np.array(test_data.iloc[:, :-1])\n",
    "Y_test = np.array(test_data.iloc[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel function:  linear\n",
      "score: 0.9285714285714286\n",
      "kernel function:  poly\n",
      "score: 0.8870967741935484\n",
      "kernel function:  rbf\n",
      "score: 0.8986175115207373\n",
      "kernel function:  sigmoid\n",
      "score: 0.7396313364055299\n"
     ]
    }
   ],
   "source": [
    "# try different kernel function to find the best one\n",
    "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "\n",
    "for kernel in kernels:\n",
    "    SVM_classifier = SVC(C = 1.0, kernel = kernel, decision_function_shape = 'ovo')\n",
    "    SVM_classifier.fit(X_train, Y_train)\n",
    "\n",
    "    print(\"kernel function: \", kernel)\n",
    "    print(\"score:\", SVM_classifier.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel function:  linear\n",
      "score: 0.9285714285714286\n",
      "kernel function:  poly\n",
      "score: 0.8778801843317973\n",
      "kernel function:  rbf\n",
      "score: 0.9193548387096774\n",
      "kernel function:  sigmoid\n",
      "score: 0.7764976958525346\n"
     ]
    }
   ],
   "source": [
    "# research the effect that standardization takes at the model\n",
    "NX_train = StandardScaler().fit_transform(X_train)\n",
    "NX_test = StandardScaler().fit_transform(X_test)\n",
    "\n",
    "for kernel in kernels:\n",
    "    SVM_classifier = SVC(C = 1.0, kernel = kernel, decision_function_shape = 'ovo')\n",
    "    SVM_classifier.fit(NX_train, Y_train)\n",
    "\n",
    "    print(\"kernel function: \", kernel)\n",
    "    print(\"score:\", SVM_classifier.score(NX_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on train set:  0.9546684709066305\n",
      "score on test set: 0.9147465437788018\n",
      "best parameter conbination:  {'C': 1.0, 'coef0': 9, 'degree': 4}\n"
     ]
    }
   ],
   "source": [
    "# use grid search to find the best parameter for poly function\n",
    "SVM_classifier = SVC(kernel = 'poly', decision_function_shape = 'ovo')\n",
    "param_grid = {'C':[1.0], 'degree':np.arange(2, 6), 'coef0':np.arange(0, 10)}\n",
    "\n",
    "algo = GridSearchCV(estimator = SVM_classifier, param_grid = param_grid, cv = 10)\n",
    "algo.fit(X_train, Y_train)\n",
    "\n",
    "print(\"score on train set: \", algo.score(X_train, Y_train))\n",
    "print(\"score on test set:\", algo.score(X_test, Y_test))\n",
    "print(\"best parameter conbination: \", algo.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
